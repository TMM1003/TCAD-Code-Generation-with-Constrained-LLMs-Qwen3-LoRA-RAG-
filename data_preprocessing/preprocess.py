# in the json dataset we have, we can see many examples include nonsense information that will not help
# the model learn

import json
import re


def clean_silvaco_output(output_text):

    lines = output_text.split("\n")
    cleaned_lines = []

    for line in lines:
        # we can skip empty lines at the beginning
        if not cleaned_lines and not line.strip():
            continue

        # any line that matches this will be skipped, pretty straight forward
        should_skip = False

        # regex for windows paths
        if re.search(r"\*\s*[A-Z]:\\", line):
            should_skip = True

        # regex for unix paths, like /home which is seen in a lot of them
        if re.search(r"^\s*[*#]\s+/[a-zA-Z0-9_/.\-]+", line):
            should_skip = True

        # gateway and netlist generators
        if "Gateway" in line and (
            "Spice Netlist Generator" in line or "Netlist Generator" in line
        ):
            should_skip = True

        # workspace name lines
        if re.search(r"\*\s*Workspace name:", line, re.IGNORECASE):
            should_skip = True

        # simulation name lines
        if re.search(r"\*\s*Simulation name:", line, re.IGNORECASE):
            should_skip = True

        # timestamp lines
        if re.search(r"\*\s*Simulation timestamp:", line, re.IGNORECASE):
            should_skip = True
        if re.search(r"\d{2}-[A-Za-z]{3}-\d{4}\s+\d{2}:\d{2}:\d{2}", line):
            should_skip = True

        # switchlist lines (another metadata field)
        if re.search(r"\*\s*Switchlist:", line, re.IGNORECASE):
            should_skip = True

        # generic end-of-netlist comments
        if line.strip() == "* End of the netlist":
            should_skip = True
        if line.strip() == "* Schematic Netlist rebuilt at runtime":
            should_skip = True

        # EXPERT generated header
        if "Victory Process Input file generated by EXPERT" in line:
            should_skip = True

        # lines that are just "##" with nothing else useful
        if re.match(r"^##\s*Victory Process Input file", line):
            should_skip = True

        if not should_skip:
            cleaned_lines.append(line)

    # Join lines back together, remove excess blank lines at beginning, remove more than 2 consecutive blank ones
    cleaned_output = "\n".join(cleaned_lines)
    cleaned_output = re.sub(r"^\n+", "", cleaned_output)
    cleaned_output = re.sub(r"\n{3,}", "\n\n", cleaned_output)

    # finish with a newline char
    if cleaned_output and not cleaned_output.endswith("\n"):
        cleaned_output += "\n"

    return cleaned_output


def preprocess_dataset(input_file, output_file):

    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    for _, example in enumerate(data):
        original_output = example["output"]
        cleaned_output = clean_silvaco_output(original_output)

        if cleaned_output != original_output:
            example["output"] = cleaned_output

    # now save
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    return data


# claude function to show how the difference (looks much better than what I can write)
def show_before_after_examples(input_file, num_examples=3):
    """
    Display before/after comparison for a few examples.
    """

    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    print("\n" + "=" * 80)
    print("BEFORE/AFTER COMPARISON")
    print("=" * 80)

    for i in range(min(num_examples, len(data))):
        example = data[i]
        original = example["output"]
        cleaned = clean_silvaco_output(original)

        if original != cleaned:
            print(f"\n--- Example {i+1} ---")
            print(f"Original length: {len(original)} chars")
            print(f"Cleaned length:  {len(cleaned)} chars")
            print(
                f"Reduction:       {len(original) - len(cleaned)} chars ({((len(original)-len(cleaned))/len(original)*100):.1f}%)"
            )
            print("\nFirst 500 chars of ORIGINAL:")
            print(original[:500])
            print("\nFirst 500 chars of CLEANED:")
            print(cleaned[:500])
            print("-" * 80)


if __name__ == "__main__":
    input_path = "../project_data/silvaco_dataset_train.json"
    output_path = "../project_data/silvaco_dataset_train_cleaned.json"

    show_before_after_examples(input_path)
    cleaned_data = preprocess_dataset(input_path, output_path)
